{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdDUAk8DNqYh6EaSxjHljM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bgalerne/mva_generative_models_for_images/blob/main/2_mva_gm_generative_prior_for_inverse_problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative prior for imaging inverse problems\n",
        "\n",
        "\n",
        "**Author:**\n",
        "\n",
        "Bruno Galerne: www.idpoisson.fr/galerne / https://github.com/bgalerne"
      ],
      "metadata": {
        "id": "j-UDPsOWavHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook we will use a generative model as an image prior to solve an imaging inverse problem.\n",
        "This amounts to limit the space of images to the subset\n",
        "$$\n",
        "\\{x = G(z),~z\\in\\mathbb{R}^k\\} \\subset \\mathbb{R}^d\n",
        "$$\n",
        "to solve a least squares inverse problem\n",
        "$$\n",
        "\\min_{x} \\|\\mathcal{A}(x) - y \\|^2.\n",
        "$$\n",
        "\n",
        "We will consider an ill-posed inverse problem close to tomography reconstruction: Reconstruct an image given the sum of its gray-levels along four directions.\n"
      ],
      "metadata": {
        "id": "d7f0k9-xa24G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative network\n",
        "\n",
        "We will consider images from the **MNIST test set** and a generative model trained as a GAN using a the disjoint **MNIST training set**.\n",
        "\n",
        "The generator is set to generate images in the range $[-1,1]$ but the real data is in the range $[0,1]$.\n",
        "Before applying the operator $\\mathcal{A}$ one must come back to the original data range (ie one does not measure negative values)."
      ],
      "metadata": {
        "id": "P5d3GuZCcw75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.autograd as autograd\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ZJ2qQFGZa2Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stretch(x):\n",
        "  # stretch values such that [min. max]->[0,1]\n",
        "  m = torch.min(x)\n",
        "  M = torch.max(x)\n",
        "  if M>m:\n",
        "    return((x-m)/(M-m))\n",
        "  else:\n",
        "    return(torch.zeros(x.shape))\n",
        "\n",
        "def imshow(img, unnormalize=True, zoom_factor=3, stretch_opt=False):\n",
        "    img = img.clone().detach().to('cpu')\n",
        "    if unnormalize:\n",
        "      img = img*0.5 + 0.5     # unnormalize\n",
        "    if stretch_opt:\n",
        "      img = stretch(img)\n",
        "    if zoom_factor!=1:\n",
        "      img = torch.kron(img, torch.ones(1,zoom_factor,zoom_factor))\n",
        "    pil_img = torchvision.transforms.functional.to_pil_image(img)\n",
        "    display(pil_img)\n",
        "    return(pil_img)\n"
      ],
      "metadata": {
        "id": "i74RIPMsdZ2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pretrained generative network:"
      ],
      "metadata": {
        "id": "YA9XsNIIdZR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c 'https://www.idpoisson.fr/galerne/mva/GAN_G_net_ep100.pth'"
      ],
      "metadata": {
        "id": "q9GATUG-fDHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator network:\n",
        "class G_Net(nn.Module):\n",
        "  def __init__(self, k):\n",
        "    super(G_Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(k, 256)\n",
        "    self.fc2 = nn.Linear(256, 512)\n",
        "    self.fc3 = nn.Linear(512, 784)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.leaky_relu(x, negative_slope=0.2)\n",
        "    x = self.fc2(x)\n",
        "    x = F.leaky_relu(x, negative_slope=0.2)\n",
        "    x = self.fc3(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = x.view(-1,1,28,28) # batch_size x channels x H x W\n",
        "    return(x)\n",
        "\n",
        "# initialize generator (with random weights)\n",
        "k = 32\n",
        "G_net = G_Net(k).to(device)\n",
        "\n",
        "def show_G_net(z=None):\n",
        "  # provide random latent code as option to see evolution\n",
        "  with torch.no_grad():\n",
        "    if z==None:\n",
        "      z = torch.randn(100,k).to(device)\n",
        "    genimages = G_net(z)\n",
        "    pil_img = imshow(torchvision.utils.make_grid(genimages.to('cpu'),nrow=10))\n",
        "    return(pil_img)\n",
        "    #print(disnet(genimages))\n",
        "print(\"Generator with random init:\")\n",
        "show_G_net();\n",
        "\n",
        "G_net.load_state_dict(torch.load('GAN_G_net_ep100.pth', map_location=device))\n",
        "G_net.eval()\n",
        "G_net.requires_grad_(False)\n",
        "print(\"Pretrained generator:\")\n",
        "show_G_net(z);\n"
      ],
      "metadata": {
        "id": "K6poLRKJeYoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operator of inverse problem\n",
        "\n",
        "We will first define the linear operator $\\mathcal{A}$ as ```opA```.\n",
        "We will consider the operator that sums the values of the gray-level image along each vertical, horizontal and diagonal directions."
      ],
      "metadata": {
        "id": "A23ZzXYBi3Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We suppose that:\n",
        "#  - the input x is a square gray-level image of size 1xMxN with M=N\n",
        "#  - the output y is 1D tensor of size number of measurements m\n",
        "\n",
        "def sum_all_diagonal_matrix(mat: torch.tensor): \n",
        "  # from: https://stackoverflow.com/questions/57347896/sum-all-diagonals-in-feature-maps-in-parallel-in-pytorch\n",
        "  n,_ = mat.shape\n",
        "  zero_mat = torch.zeros((n, n),device=mat.device) # Zero matrix used for padding\n",
        "  mat_padded =  torch.cat((zero_mat, mat, zero_mat), 1) # pads the matrix on left and right\n",
        "  mat_strided = mat_padded.as_strided((n, 2*n), (3*n + 1, 1)) # Change the strides\n",
        "  sum_diags = torch.sum(mat_strided, 0) # Sums the resulting matrix's columns\n",
        "  return(sum_diags[1:])\n",
        "\n",
        "def axial_and_diagonal_sum(x):\n",
        "  # sum over diagoanal:\n",
        "  _,M,N = x.shape\n",
        "  xmat = x.reshape(M,N)\n",
        "  yhori = torch.sum(x, axis=2).flatten()\n",
        "  yvert = torch.sum(x, axis=1).flatten()\n",
        "  ydiag = sum_all_diagonal_matrix(xmat).flatten()\n",
        "  y_anti_diag = sum_all_diagonal_matrix(xmat.flip(1)).flatten()\n",
        "  y = torch.cat((yhori, yvert, ydiag, y_anti_diag.flip(0)))\n",
        "  return(y)\n",
        "\n",
        "# test of axial_and_diagonal_sum(x)\n",
        "t = torch.diag(1+torch.arange(4)).unsqueeze(0)\n",
        "print(\"Test of axial_and_diagonal_sum(x):\")\n",
        "print(\"Input:\", t)\n",
        "print(\"Output:\", axial_and_diagonal_sum(t))      \n",
        "\n",
        "opA = axial_and_diagonal_sum\n",
        "\n",
        "def batchopA(x):\n",
        "  # apply opA to each image of a batch and return a tensor:\n",
        "  listAx = []\n",
        "  for bidx in range(x.shape[0]):\n",
        "    listAx.append(opA(x[bidx,:,:]))\n",
        "  Ax = torch.stack(listAx)\n",
        "  return(Ax)\n"
      ],
      "metadata": {
        "id": "zNwZTqkpi7za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input data"
      ],
      "metadata": {
        "id": "eS5NDkmsiUhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input\n",
        "transformtest = transforms.ToTensor()\n",
        "datatest = datasets.MNIST('.', train=False, download=True, transform=transformtest)\n",
        "input_idx = 0 # a seven\n",
        "#input_idx = 99 # a nine\n",
        "#input_idx = 3 # a zero\n",
        "#input_idx = 5 # a one\n",
        "#input_idx = 21 # a six\n",
        "#input_idx = 1 # a two\n",
        "#input_idx = 4 # a four\n",
        "#input_idx = 1984 # an unusual 2, hard\n",
        "\n",
        "\n",
        "xstar_im =  datatest[input_idx][0].to(device)\n",
        "imshow(xstar_im, False);\n",
        "_, M, N = xstar_im.shape\n",
        "d = M*N\n",
        "\n",
        "y = opA(xstar_im)\n",
        "noise = 0.5*torch.randn(y.shape, device=device)\n",
        "ynoisy = y+noise\n",
        "\n",
        "print('Plot of y: (yhori, yvert, ydiag, y_anti_diag)')\n",
        "plt.figure(figsize=(20,4))\n",
        "plt.bar(range(y.numel()), y.to('cpu').numpy());\n"
      ],
      "metadata": {
        "id": "PtUv9r9Zeny3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pseudo-inverse of operator\n",
        "\n",
        "Let us recall that the Moore-Penrose pseudo-inverse $\\mathcal{A}^+$ is such that $\\mathcal{A}^+ y$ is a least-square solution with minimal norm\n",
        "$$\n",
        "\\min_{x\\in\\mathbb{R}^{d}} \\|\\mathcal{A}(x) - y \\|^2 \\quad \\text{s.t.}\\quad\\text{$\\|x\\|$ is minimal}.\n",
        "$$\n",
        "One can compute $\\mathcal{A}^+ y$ by applying gradient descent to the convex function\n",
        "$$\n",
        "f(x) = \\|\\mathcal{A}(x) - y \\|^2\n",
        "$$\n",
        "(as long as the descent step is smaller than $1/L$ the Lipschitz constant of the gradient).\n"
      ],
      "metadata": {
        "id": "4Em6PzSBL9tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(xstar_im.shape).to(device)\n",
        "x.requires_grad = True\n",
        "\n",
        "# compute pseudo-inverse of y\n",
        "optimizer = optim.SGD([x], lr = 0.01, momentum = 0.9)\n",
        "niter = 1000\n",
        "for it in range(niter):\n",
        "  optimizer.zero_grad()\n",
        "  fx = torch.sum((opA(x)-y)**2)\n",
        "  fx.backward()\n",
        "  optimizer.step()\n",
        "  if fx.item()<1e-10:\n",
        "    print(\"Convergence reached:\")\n",
        "    print(\"iteration \", it, \"fx = \", fx.item())\n",
        "    imshow(x, stretch_opt=True);\n",
        "    break\n",
        "  if it%(niter//10) == niter//10-1:\n",
        "    print(\"iteration \", it, \"fx = \", fx.item())\n",
        "    imshow(x, stretch_opt=True);\n"
      ],
      "metadata": {
        "id": "5EkMH-U8ij4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN prior for solving the inverse problem\n",
        "We solve for\n",
        "$$\n",
        "\\hat x = G(\\hat z)\n",
        "\\quad \\text{with $\\hat z$ solution of}\\quad \n",
        "\\min_{z\\in\\mathbb{R}^{k}} \\|\\mathcal{A}(G(z)) - y \\|^2.\n",
        "$$\n",
        "Since the result highly depends on the initialization, we will optimize for a batch of $b=10$ $z$ values.\n",
        "\n",
        "**Exercise:**\n",
        "Implement a script that:\n",
        "1. Initialize an array $z = (z^0, \\dots, z^{b-1})$ of $b$ random latent code.\n",
        "2. Optimize for $Z$ to minimize the sum\n",
        "$$\n",
        "\\sum_{j=0}^{b-1} \\|\\mathcal{A}(G(z^j)) - y \\|^2\n",
        "$$\n",
        "using ```optim.Adam([z], lr = 0.01)``` as optimizer for ```niter = 10**4```.\n",
        "3. Display the $b=10$ corresponding images $G(z^j)$ at initialization and at 10 intermediary steps as well as the iteration number and the value of the function to optimize.\n",
        "\n",
        "Be carefull that $\\mathcal{A}$ should be applied to images with range $[0,1]$.\n"
      ],
      "metadata": {
        "id": "EmbLYpbBY7an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = 10 # batch size:\n",
        "z = torch.rand(b,k, device=device)\n",
        "z.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam([z], lr = 0.01)\n",
        "\n",
        "print('Solution:')\n",
        "imshow(xstar_im, False);\n",
        "niter = 10**4\n",
        "for it in range(niter):\n",
        "\n",
        "  #TODO\n",
        "\n",
        "  \n",
        "  if it==0 or it%(niter//10) == niter//10-1:\n",
        "    print(\"iteration \", it, \"fx = \", fx.item())\n",
        "    show_G_net(z=z)\n",
        "\n"
      ],
      "metadata": {
        "id": "HBpesFygYV2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity to noise\n",
        "\n",
        "**Exercise:** Experiment if the pseudo-inverse and the output obtained with generative prior are sensible with respect to noisy measurements."
      ],
      "metadata": {
        "id": "pdowLxTdYRPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity to generator\n",
        "\n",
        "**Exercise:**\n",
        "1. Evaluate the FID score of the generator that is approximate.\n",
        "2. Find a pretrained generative model online with better FID score and use it to improve the results (but make sure that the network is deterministic in evaluation mode)."
      ],
      "metadata": {
        "id": "Cn7I_Mgpx4Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbOuZtxbybKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}